{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocess import DataPreprocessor\n",
    "import os\n",
    "import random\n",
    "# from embeddings_generator import *\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "history_length = 12 # N in article\n",
    "ra_length = 4 # K in article\n",
    "discount_factor = 0.99 # Gamma in Bellman equation\n",
    "actor_lr = 0.0001\n",
    "critic_lr = 0.001\n",
    "tau = 0.001 # τ in Algorithm 3\n",
    "batch_size = 64\n",
    "nb_episodes = 100\n",
    "nb_rounds = 50\n",
    "filename_summary = 'summary.txt'\n",
    "alpha = 0.5 # α (alpha) in Equation (1)\n",
    "gamma = 0.9 # Γ (Gamma) in Equation (4)\n",
    "buffer_size = 1000000 # Size of replay memory D in article\n",
    "fixed_length = True # Fixed memory length\n",
    "\n",
    "dg = DataPreprocessor(os.path.dirname(os.getcwd())+'/data/ml-100k/u.data', os.path.dirname(os.getcwd())+'/data/ml-100k/u.item')\n",
    "# dg.write_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.write_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_histo_v5(user_histo, pivot_rating=4, nb_states=5):\n",
    "    prop_histo = user_histo[user_histo['rating'] >= pivot_rating]\n",
    "    if len(prop_histo) > nb_states:\n",
    "        user = user_histo['userId'][0]\n",
    "        initial_state =  prop_histo[0:nb_states]['itemId'].values.tolist()\n",
    "        user_history =  prop_histo[nb_states:]['itemId'].values.tolist()\n",
    "    return user, initial_state, user_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "initial_states = []\n",
    "user_histories = []\n",
    "\n",
    "for user_histo in dg.histo:\n",
    "    try:\n",
    "        user, init_state, u_history = sample_histo_v5(user_histo)\n",
    "        users.append(user)\n",
    "        initial_states.append(init_state)\n",
    "        user_histories.append(u_history)\n",
    "    except:\n",
    "#         print(len(user_histo[user_histo['rating'] >= 4]))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_histo = dg.histo[0]\n",
    "u_df = sample_histo_v6(user_histo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>slate</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>[241, 268, 285, 305, 339]</td>\n",
       "      <td>[0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195</td>\n",
       "      <td>[1021, 250, 256, 1006, 1240]</td>\n",
       "      <td>[1, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>[427, 380, 201, 284, 7]</td>\n",
       "      <td>[1, 1, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>[115, 654, 110, 152, 172]</td>\n",
       "      <td>[0, 1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195</td>\n",
       "      <td>[237, 69, 381, 392, 286]</td>\n",
       "      <td>[1, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                         slate           action\n",
       "0   195     [241, 268, 285, 305, 339]  [0, 0, 1, 1, 0]\n",
       "1   195  [1021, 250, 256, 1006, 1240]  [1, 0, 0, 1, 0]\n",
       "2   195       [427, 380, 201, 284, 7]  [1, 1, 0, 1, 1]\n",
       "3   195     [115, 654, 110, 152, 172]  [0, 1, 1, 1, 0]\n",
       "4   195      [237, 69, 381, 392, 286]  [1, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_df[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def sample_histo_v6(user_histo, pivot_rating=4, nb_states=5):\n",
    "    binary_ratings = [1 if i>=4 else 0 for i in user_histo['rating']]\n",
    "    user = user_histo['userId'][0]\n",
    "    items = user_histo['itemId'].values.tolist()\n",
    "    users = []\n",
    "    slates = []\n",
    "    actions = []\n",
    "    for i in range(0,len(items),5):\n",
    "        if i+5 <= len(items):\n",
    "            slate = items[i:i+5]\n",
    "            action = binary_ratings[i:i+5]\n",
    "            slates.append(slate)\n",
    "            actions.append(action)\n",
    "            users.append(user)\n",
    "            \n",
    "    user_df = pd.DataFrame()\n",
    "    user_df['user'] = users\n",
    "    user_df['slate'] = slates\n",
    "    user_df['action'] = actions\n",
    "    return user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "train_test_ratio = 0.9\n",
    "for user_histo in dg.histo: \n",
    "    u_df = sample_histo_v6(user_histo)\n",
    "    split_point = int(train_test_ratio*len(u_df))\n",
    "    u_train_df = u_df[0:split_point]\n",
    "    u_test_df = u_df[split_point:]\n",
    "    train_data.append(u_train_df)\n",
    "    test_data.append(u_test_df)\n",
    "train_df = pd.concat(train_data)\n",
    "test_df = pd.concat(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./train_data.csv', index=False)\n",
    "test_df.to_csv('./test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = 0.8\n",
    "\n",
    "train_data['user'] = users\n",
    "train_data['state'] = initial_states\n",
    "train_data['history'] = [u_h[0:int(train_test_ratio*len(u_h))] for u_h in user_histories]\n",
    "\n",
    "test_data['user'] = users\n",
    "test_data['state'] = initial_states\n",
    "test_data['history'] = [u_h[int(train_test_ratio*len(u_h)):] for u_h in user_histories]\n",
    "\n",
    "# test_data\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('./data/train_data.csv', index=False)\n",
    "test_data.to_csv('./data/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>state</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>389</td>\n",
       "      <td>[302, 127, 100, 50, 475]</td>\n",
       "      <td>[181, 847, 1007, 1, 275, 845, 124, 285, 471, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>894</td>\n",
       "      <td>[242, 302, 258, 262, 879]</td>\n",
       "      <td>[292, 690, 328, 300, 515, 1251, 1379, 534, 333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384</td>\n",
       "      <td>[272, 302, 333, 347, 286]</td>\n",
       "      <td>[258, 313, 327, 300, 879, 989, 748, 355, 316, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658</td>\n",
       "      <td>[515, 100, 276, 9, 127]</td>\n",
       "      <td>[1, 408, 475, 257, 50, 7, 117, 471, 467, 171, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>711</td>\n",
       "      <td>[258, 286, 181, 50, 475]</td>\n",
       "      <td>[283, 676, 1115, 476, 275, 744, 151, 25, 10, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                      state  \\\n",
       "0   389   [302, 127, 100, 50, 475]   \n",
       "1   894  [242, 302, 258, 262, 879]   \n",
       "2   384  [272, 302, 333, 347, 286]   \n",
       "3   658    [515, 100, 276, 9, 127]   \n",
       "4   711   [258, 286, 181, 50, 475]   \n",
       "\n",
       "                                             history  \n",
       "0  [181, 847, 1007, 1, 275, 845, 124, 285, 471, 2...  \n",
       "1  [292, 690, 328, 300, 515, 1251, 1379, 534, 333...  \n",
       "2  [258, 313, 327, 300, 879, 989, 748, 355, 316, ...  \n",
       "3  [1, 408, 475, 257, 50, 7, 117, 471, 467, 171, ...  \n",
       "4  [283, 676, 1115, 476, 275, 744, 151, 25, 10, 1...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.read_csv('./data/train_data.csv')\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_histo_v1(user_histo, action_ratio=0.8, max_samp_by_user=5,  max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
    "    '''\n",
    "    For a given historic, make one or multiple sampling.\n",
    "    If no optional argument given for nb_states and nb_actions, then the sampling\n",
    "    is random and each sample can have differents size for action and state.\n",
    "    To normalize sampling we need to give list of the numbers of states and actions\n",
    "    to be sampled.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_histo :  DataFrame\n",
    "                      historic of user\n",
    "    delimiter :       string, optional\n",
    "                      delimiter for the csv\n",
    "    action_ratio :    float, optional\n",
    "                      ratio form which movies in history will be selected\n",
    "    max_samp_by_user: int, optional\n",
    "                      Number max of sample to make by user\n",
    "    max_state :       int, optional\n",
    "                      Number max of movies to take for the 'state' column\n",
    "    max_action :      int, optional\n",
    "                      Number max of movies to take for the 'action' action\n",
    "    nb_states :       array(int), optional\n",
    "                      Numbers of movies to be taken for each sample made on user's historic\n",
    "    nb_actions :      array(int), optional\n",
    "                      Numbers of rating to be taken for each sample made on user's historic\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    states :         List(String)\n",
    "                     All the states sampled, format of a sample: itemId&rating\n",
    "    actions :        List(String)\n",
    "                     All the actions sampled, format of a sample: itemId&rating\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    States must be before(timestamp<) the actions.\n",
    "    If given, size of nb_states is the numbller of sample by user\n",
    "    sizes of nb_states and nb_actions must be equals\n",
    "    '''\n",
    "\n",
    "    n = len (user_histo)\n",
    "    sep = int (action_ratio * n)\n",
    "    nb_sample = random.randint (1, max_samp_by_user)\n",
    "    if not nb_states:\n",
    "        nb_states = [min (random.randint (1, sep), max_state) for i in range (nb_sample)]\n",
    "    if not nb_actions:\n",
    "        nb_actions = [min (random.randint (1, n - sep), max_action) for i in range (nb_sample)]\n",
    "    assert len (nb_states) == len (nb_actions), 'Given array must have the same size'\n",
    "\n",
    "    states = []\n",
    "    actions = []\n",
    "    # SELECT SAMPLES IN HISTO\n",
    "    for i in range (len (nb_states)):\n",
    "        sample_states = user_histo.iloc[0:sep].sample (nb_states[i])\n",
    "        sample_actions = user_histo.iloc[-(n - sep):].sample (nb_actions[i])\n",
    "\n",
    "        sample_state = []\n",
    "        sample_action = []\n",
    "        for j in range (nb_states[i]):\n",
    "            row = sample_states.iloc[j]\n",
    "            # FORMAT STATE\n",
    "            state = str (row.loc['itemId']) + '&' + str (row.loc['rating'])\n",
    "            sample_state.append (state)\n",
    "\n",
    "        for j in range (nb_actions[i]):\n",
    "            row = sample_actions.iloc[j]\n",
    "            # FORMAT ACTION\n",
    "            action = str (row.loc['itemId']) + '&' + str (row.loc['rating'])\n",
    "            sample_action.append (action)\n",
    "\n",
    "\n",
    "        states.append (sample_state)\n",
    "        actions.append (sample_action)\n",
    "\n",
    "    return states, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_histo_v2(user_histo, action_ratio=0.8, max_samp_by_user=5,  max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
    "    '''\n",
    "    For a given historic, make one or multiple sampling.\n",
    "    If no optional argument given for nb_states and nb_actions, then the sampling\n",
    "    is random and each sample can have differents size for action and state.\n",
    "    To normalize sampling we need to give list of the numbers of states and actions\n",
    "    to be sampled.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_histo :  DataFrame\n",
    "                      historic of user\n",
    "    delimiter :       string, optional\n",
    "                      delimiter for the csv\n",
    "    action_ratio :    float, optional\n",
    "                      ratio form which movies in history will be selected\n",
    "    max_samp_by_user: int, optional\n",
    "                      Number max of sample to make by user\n",
    "    max_state :       int, optional\n",
    "                      Number max of movies to take for the 'state' column\n",
    "    max_action :      int, optional\n",
    "                      Number max of movies to take for the 'action' action\n",
    "    nb_states :       array(int), optional\n",
    "                      Numbers of movies to be taken for each sample made on user's historic\n",
    "    nb_actions :      array(int), optional\n",
    "                      Numbers of rating to be taken for each sample made on user's historic\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    states :         List(String)\n",
    "                     All the states sampled, format of a sample: itemId&rating\n",
    "    actions :        List(String)\n",
    "                     All the actions sampled, format of a sample: itemId&rating\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    States must be before(timestamp<) the actions.\n",
    "    If given, size of nb_states is the numbller of sample by user\n",
    "    sizes of nb_states and nb_actions must be equals\n",
    "    '''\n",
    "\n",
    "    n = len(user_histo)\n",
    "    sep = int (action_ratio * n)\n",
    "    nb_sample = random.randint (1, max_samp_by_user)\n",
    "    if not nb_states:\n",
    "        nb_states = [min (random.randint (1, sep), max_state) for i in range (nb_sample)]\n",
    "    if not nb_actions:\n",
    "        nb_actions = [min (random.randint (1, n - sep), max_action) for i in range (nb_sample)]\n",
    "    assert len (nb_states) == len (nb_actions), 'Given array must have the same size'\n",
    "    \n",
    "    states = []\n",
    "    actions = []\n",
    "    for i in range (len (nb_states)):\n",
    "        user_states = user_histo[user_histo['rating']>=4]\n",
    "        if len(user_states) >= nb_states[i]:\n",
    "            sample_states = user_states.sample (nb_states[i])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        sample_actions = user_histo.iloc[-(n - sep):].sample (nb_actions[i])\n",
    "\n",
    "        sample_state = []\n",
    "        sample_action = []\n",
    "\n",
    "        for j in range (nb_states[i]):\n",
    "            row = sample_states.iloc[j]\n",
    "            # FORMAT STATE\n",
    "            state = str (row.loc['itemId']) + '&' + str (1)\n",
    "            sample_state.append (state)\n",
    "\n",
    "        for k in range (nb_actions[i]):\n",
    "            row = sample_actions.iloc[k]\n",
    "            # FORMAT ACTION\n",
    "            if row.loc['rating'] >= 4:\n",
    "                action = str (row.loc['itemId']) + '&' + str (1)\n",
    "            else:\n",
    "                action = str (row.loc['itemId']) + '&' + str (0)\n",
    "            sample_action.append (action)\n",
    "\n",
    "        states.append (sample_state)\n",
    "        actions.append (sample_action)\n",
    "    return states, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "def sample_histo_v3(user_histo, action_ratio=0.8, max_samp_by_user=5,  max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
    "    '''\n",
    "    For a given historic, make one or multiple sampling.\n",
    "    If no optional argument given for nb_states and nb_actions, then the sampling\n",
    "    is random and each sample can have differents size for action and state.\n",
    "    To normalize sampling we need to give list of the numbers of states and actions\n",
    "    to be sampled.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_histo :  DataFrame\n",
    "                      historic of user\n",
    "    delimiter :       string, optional\n",
    "                      delimiter for the csv\n",
    "    action_ratio :    float, optional\n",
    "                      ratio form which movies in history will be selected\n",
    "    max_samp_by_user: int, optional\n",
    "                      Number max of sample to make by user\n",
    "    max_state :       int, optional\n",
    "                      Number max of movies to take for the 'state' column\n",
    "    max_action :      int, optional\n",
    "                      Number max of movies to take for the 'action' action\n",
    "    nb_states :       array(int), optional\n",
    "                      Numbers of movies to be taken for each sample made on user's historic\n",
    "    nb_actions :      array(int), optional\n",
    "                      Numbers of rating to be taken for each sample made on user's historic\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    states :         List(String)\n",
    "                     All the states sampled, format of a sample: itemId&rating\n",
    "    actions :        List(String)\n",
    "                     All the actions sampled, format of a sample: itemId&rating\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    States must be before(timestamp<) the actions.\n",
    "    If given, size of nb_states is the numbller of sample by user\n",
    "    sizes of nb_states and nb_actions must be equals\n",
    "    '''\n",
    "\n",
    "    n = len(user_histo)\n",
    "    sep = int (action_ratio * n)\n",
    "    nb_sample = random.randint (1, max_samp_by_user)\n",
    "    if not nb_states:\n",
    "        nb_states = [min (random.randint (1, sep), max_state) for i in range (nb_sample)]\n",
    "    if not nb_actions:\n",
    "        nb_actions = [min (random.randint (1, n - sep), max_action) for i in range (nb_sample)]\n",
    "    assert len (nb_states) == len (nb_actions), 'Given array must have the same size'\n",
    "    \n",
    "    states = []\n",
    "    for n in range(len(nb_states)):\n",
    "        state_len = nb_states[n]\n",
    "        action_len = nb_actions[n]\n",
    "\n",
    "        item_list = user_histo['itemId'].values.tolist()\n",
    "        click_list = user_histo['rating'].values.tolist()\n",
    "        initial_state = []\n",
    "        initial_end = 0\n",
    "        for i in range(len(item_list)):\n",
    "            if click_list[i] >= 4 and len(initial_state) < state_len:\n",
    "                initial_state.append(item_list[i])\n",
    "                initial_end = i\n",
    "        \n",
    "\n",
    "\n",
    "        if len(initial_state) == state_len and (initial_end + action_len <= len(item_list)):\n",
    "            current_state = copy.copy(initial_state)\n",
    "            for i in range(initial_end+1,len(item_list),action_len):\n",
    "                if i+action_len <= len(item_list):\n",
    "                    actions.append([str(item) + '&' + str (1) if rating >= 4 else str(item) + '&' + str (0) for item,rating in zip(item_list[i:i+action_len],click_list[i:i+action_len])])\n",
    "                    rewards.append(click_list[i:i+action_len])\n",
    "                    states.append([str(i) + '&' + str (1) for i in copy.copy(current_state)])\n",
    "                    for j in range(i,i+action_len):\n",
    "                        if click_list[j] == 1:\n",
    "                            current_state.append(item_list[j])\n",
    "                            del current_state[0]\n",
    "            return states, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "def sample_histo_v4(user_histo, action_ratio=0.8, max_samp_by_user=5,  max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
    "    '''\n",
    "    For a given historic, make one or multiple sampling.\n",
    "    If no optional argument given for nb_states and nb_actions, then the sampling\n",
    "    is random and each sample can have differents size for action and state.\n",
    "    To normalize sampling we need to give list of the numbers of states and actions\n",
    "    to be sampled.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_histo :  DataFrame\n",
    "                      historic of user\n",
    "    delimiter :       string, optional\n",
    "                      delimiter for the csv\n",
    "    action_ratio :    float, optional\n",
    "                      ratio form which movies in history will be selected\n",
    "    max_samp_by_user: int, optional\n",
    "                      Number max of sample to make by user\n",
    "    max_state :       int, optional\n",
    "                      Number max of movies to take for the 'state' column\n",
    "    max_action :      int, optional\n",
    "                      Number max of movies to take for the 'action' action\n",
    "    nb_states :       array(int), optional\n",
    "                      Numbers of movies to be taken for each sample made on user's historic\n",
    "    nb_actions :      array(int), optional\n",
    "                      Numbers of rating to be taken for each sample made on user's historic\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    states :         List(String)\n",
    "                     All the states sampled, format of a sample: itemId&rating\n",
    "    actions :        List(String)\n",
    "                     All the actions sampled, format of a sample: itemId&rating\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    States must be before(timestamp<) the actions.\n",
    "    If given, size of nb_states is the numbller of sample by user\n",
    "    sizes of nb_states and nb_actions must be equals\n",
    "    '''\n",
    "\n",
    "    n = len(user_histo)\n",
    "    sep = int (action_ratio * n)\n",
    "    nb_sample = random.randint (1, max_samp_by_user)\n",
    "    if not nb_states:\n",
    "        nb_states = [min (random.randint (1, sep), max_state) for i in range (nb_sample)]\n",
    "    if not nb_actions:\n",
    "        nb_actions = [min (random.randint (1, n - sep), max_action) for i in range (nb_sample)]\n",
    "    assert len (nb_states) == len (nb_actions), 'Given array must have the same size'\n",
    "    \n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    \n",
    "    user = [[str(int(user_histo['userId'].values.tolist()[0])) + '&' + str (1)]]\n",
    "    \n",
    "    for n in range(len(nb_states)):\n",
    "        state_len = nb_states[n]\n",
    "        action_len = nb_actions[n]\n",
    "\n",
    "        item_list = user_histo['itemId'].values.tolist()\n",
    "        click_list = user_histo['rating'].values.tolist()\n",
    "        initial_state = []\n",
    "        initial_end = 0\n",
    "        for i in range(len(item_list)):\n",
    "            if click_list[i] >= 4 and len(initial_state) < state_len:\n",
    "                initial_state.append(item_list[i])\n",
    "                initial_end = i\n",
    "\n",
    "\n",
    "\n",
    "        if len(initial_state) == state_len:\n",
    "            states.append([str(i) + '&' + str (1) for i in initial_state])\n",
    "            return user,states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_histo = dg.train[0]\n",
    "action_ratio=0.8\n",
    "max_samp_by_user=5\n",
    "max_state=100\n",
    "max_action=50\n",
    "nb_states=[12]\n",
    "nb_actions=[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len (user_histo)\n",
    "sep = int (action_ratio * n)\n",
    "nb_sample = random.randint (1, max_samp_by_user)\n",
    "n,sep,nb_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not nb_states:\n",
    "    nb_states = [min (random.randint (1, sep), max_state) for i in range (nb_sample)]\n",
    "if not nb_actions:\n",
    "    nb_actions = [min (random.randint (1, n - sep), max_action) for i in range (nb_sample)]\n",
    "assert len (nb_states) == len (nb_actions), 'Given array must have the same size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['195&1']]\n",
      "[['285&1', '305&1', '1021&1', '1006&1', '427&1']]\n",
      "[['185&1']]\n",
      "[['299&1', '321&1', '590&1', '290&1', '99&1']]\n",
      "[['21&1']]\n",
      "[['257&1', '185&1', '172&1', '152&1', '237&1']]\n",
      "[['243&1']]\n",
      "[['267&1', '885&1', '323&1', '257&1', '293&1']]\n",
      "[['165&1']]\n",
      "[['312&1', '257&1', '346&1', '750&1', '327&1']]\n",
      "[['297&1']]\n",
      "[['285&1', '171&1', '587&1', '173&1', '68&1']]\n",
      "[['114&1']]\n",
      "[['301&1', '136&1', '627&1', '272&1', '695&1']]\n",
      "[['252&1']]\n",
      "[['299&1', '688&1', '327&1', '342&1', '293&1']]\n",
      "[['304&1']]\n",
      "[['285&1', '241&1', '689&1', '301&1', '903&1']]\n",
      "[['5&1']]\n",
      "[['241&1', '268&1', '301&1', '305&1', '303&1']]\n",
      "[['61&1']]\n",
      "[['257&1', '305&1', '874&1', '474&1', '272&1']]\n",
      "[['285&1']]\n",
      "[['288&1', '287&1', '407&1', '247&1', '150&1']]\n",
      "[['199&1']]\n",
      "[['303&1', '257&1', '324&1', '124&1', '275&1']]\n",
      "[['209&1']]\n",
      "[['299&1', '22&1', '57&1', '968&1', '55&1']]\n",
      "[['223&1']]\n",
      "[['312&1', '299&1', '327&1', '293&1', '325&1']]\n",
      "[['302&1']]\n",
      "[['257&1', '285&1', '301&1', '268&1', '287&1']]\n",
      "[['121&1']]\n",
      "[['268&1', '27&1', '512&1', '174&1', '510&1']]\n",
      "[['193&1']]\n",
      "[['293&1', '495&1', '658&1', '126&1', '434&1']]\n",
      "[['290&1']]\n",
      "[['287&1', '324&1', '236&1', '474&1', '128&1']]\n",
      "[['233&1']]\n",
      "[['312&1', '241&1', '291&1', '288&1', '315&1']]\n",
      "[['118&1']]\n",
      "[['299&1', '285&1', '321&1', '322&1', '457&1']]\n",
      "[['166&1']]\n",
      "[['236&1', '221&1', '136&1', '85&1', '380&1']]\n",
      "[['298&1']]\n",
      "[['285&1', '299&1', '126&1', '250&1', '149&1']]\n",
      "[['307&1']]\n",
      "[['287&1', '318&1', '640&1', '1020&1', '168&1']]\n",
      "[['94&1']]\n",
      "[['180&1', '682&1', '150&1', '285&1', '472&1']]\n",
      "[['37&1']]\n",
      "[['915&1', '287&1', '312&1', '293&1', '677&1']]\n",
      "[['101&1']]\n",
      "[['257&1', '318&1', '611&1', '306&1', '587&1']]\n",
      "[['62&1']]\n",
      "[['285&1', '332&1', '261&1', '747&1', '300&1']]\n",
      "[['159&1']]\n",
      "[['407&1', '99&1', '136&1', '951&1', '123&1']]\n",
      "[['49&1']]\n",
      "[['267&1', '318&1', '287&1', '323&1', '474&1']]\n",
      "[['300&1']]\n",
      "[['6&1', '249&1', '108&1', '126&1', '180&1']]\n",
      "[['224&1']]\n",
      "[['285&1', '478&1', '426&1', '236&1', '97&1']]\n",
      "[['289&1']]\n",
      "[['227&1', '229&1', '49&1', '992&1', '70&1']]\n",
      "[['96&1']]\n",
      "[['134&1', '407&1', '481&1', '167&1', '429&1']]\n",
      "[['156&1']]\n",
      "[['285&1', '514&1', '0&1', '234&1', '149&1']]\n",
      "[['180&1']]\n",
      "[['287&1', '269&1', '288&1', '681&1', '219&1']]\n",
      "[['277&1']]\n",
      "[['312&1', '314&1', '346&1', '268&1', '305&1']]\n",
      "[['275&1']]\n",
      "[['257&1', '299&1', '293&1', '327&1', '287&1']]\n",
      "[['6&1']]\n",
      "[['265&1', '285&1', '679&1', '306&1', '299&1']]\n",
      "[['9&1']]\n",
      "[['301&1', '268&1', '285&1', '288&1', '244&1']]\n",
      "[['283&1']]\n",
      "[['285&1', '346&1', '271&1', '344&1', '261&1']]\n",
      "[['200&1']]\n",
      "[['241&1', '312&1', '267&1', '301&1', '990&1']]\n",
      "[['286&1']]\n",
      "[['747&1', '293&1', '326&1', '245&1', '247&1']]\n",
      "[['245&1']]\n",
      "[['49&1', '0&1', '177&1', '918&1', '180&1']]\n",
      "[['241&1']]\n",
      "[['293&1', '0&1', '282&1', '236&1', '739&1']]\n",
      "[['248&1']]\n",
      "[['241&1', '257&1', '301&1', '326&1', '299&1']]\n",
      "[['98&1']]\n",
      "[['287&1', '312&1', '750&1', '299&1', '345&1']]\n",
      "[['177&1']]\n",
      "[['330&1', '299&1', '268&1', '750&1', '257&1']]\n",
      "[['250&1']]\n",
      "[['312&1', '299&1', '287&1', '63&1', '171&1']]\n",
      "[['80&1']]\n",
      "[['146&1', '282&1', '474&1', '275&1', '6&1']]\n",
      "[['259&1']]\n",
      "[['312&1', '332&1', '747&1', '325&1', '349&1']]\n",
      "[['24&1']]\n",
      "[['268&1', '479&1', '603&1', '182&1', '133&1']]\n",
      "[['58&1']]\n",
      "[['312&1', '287&1', '899&1', '125&1', '99&1']]\n",
      "[['71&1']]\n",
      "[['24&1', '684&1', '128&1', '470&1', '116&1']]\n",
      "[['86&1']]\n",
      "[['179&1', '134&1', '198&1', '522&1', '47&1']]\n",
      "[['41&1']]\n",
      "[['293&1', '124&1', '470&1', '117&1', '404&1']]\n",
      "[['291&1']]\n",
      "[['330&1', '299&1', '78&1', '175&1', '182&1']]\n",
      "[['19&1']]\n",
      "[['322&1', '677&1', '242&1', '180&1', '14&1']]\n",
      "[['12&1']]\n",
      "[['309&1', '267&1', '301&1', '304&1', '873&1']]\n",
      "[['137&1']]\n",
      "[['110&1', '99&1', '0&1', '136&1', '284&1']]\n",
      "[['59&1']]\n",
      "[['285&1', '326&1', '600&1', '143&1', '131&1']]\n",
      "[['56&1']]\n",
      "[['287&1', '293&1', '320&1', '747&1', '244&1']]\n",
      "[['222&1']]\n",
      "[['332&1', '308&1', '312&1', '331&1', '681&1']]\n",
      "[['188&1']]\n",
      "[['99&1', '13&1', '49&1', '126&1', '245&1']]\n",
      "[['242&1']]\n",
      "[['285&1', '267&1', '126&1', '245&1', '0&1']]\n",
      "[['91&1']]\n",
      "[['627&1', '49&1', '474&1', '8&1', '410&1']]\n",
      "[['240&1']]\n",
      "[['285&1', '749&1', '267&1', '309&1', '886&1']]\n",
      "[['253&1']]\n",
      "[['312&1', '180&1', '49&1', '221&1', '135&1']]\n",
      "[['292&1']]\n",
      "[['312&1', '301&1', '271&1', '302&1', '126&1']]\n",
      "[['126&1']]\n",
      "[['293&1', '287&1', '900&1', '257&1', '299&1']]\n",
      "[['221&1']]\n",
      "[['257&1', '267&1', '327&1', '299&1', '332&1']]\n",
      "[['266&1']]\n",
      "[['474&1', '249&1', '99&1', '123&1', '272&1']]\n",
      "[['10&1']]\n",
      "[['285&1', '749&1', '267&1', '257&1', '689&1']]\n",
      "[['7&1']]\n",
      "[['257&1', '300&1', '688&1', '337&1', '186&1']]\n",
      "[['161&1']]\n",
      "[['24&1', '49&1', '507&1', '297&1', '221&1']]\n",
      "[['278&1']]\n",
      "[['320&1', '407&1', '99&1', '150&1', '247&1']]\n",
      "[['144&1']]\n",
      "[['257&1', '241&1', '298&1', '326&1', '687&1']]\n",
      "[['27&1']]\n",
      "[['257&1', '270&1', '195&1', '30&1', '10&1']]\n",
      "[['134&1']]\n",
      "[['293&1', '326&1', '320&1', '324&1', '257&1']]\n",
      "[['31&1']]\n",
      "[['267&1', '312&1', '287&1', '49&1', '245&1']]\n",
      "[['89&1']]\n",
      "[['339&1', '271&1', '312&1', '310&1', '302&1']]\n",
      "[['215&1']]\n",
      "[['99&1', '281&1', '128&1', '0&1', '8&1']]\n",
      "[['249&1']]\n",
      "[['257&1', '287&1', '320&1', '259&1', '987&1']]\n",
      "[['270&1']]\n",
      "[['345&1', '689&1', '301&1', '268&1', '241&1']]\n",
      "[['264&1']]\n",
      "[['299&1', '257&1', '287&1', '293&1', '327&1']]\n",
      "[['197&1']]\n",
      "[['257&1', '126&1', '49&1', '180&1', '0&1']]\n",
      "[['167&1']]\n",
      "[['312&1', '293&1', '257&1', '299&1', '180&1']]\n",
      "[['109&1']]\n",
      "[['271&1', '287&1', '312&1', '257&1', '306&1']]\n",
      "[['57&1']]\n",
      "[['268&1', '312&1', '267&1', '8&1', '49&1']]\n",
      "[['236&1']]\n",
      "[['356&1', '133&1', '473&1', '97&1', '512&1']]\n",
      "[['93&1']]\n",
      "[['482&1', '190&1', '126&1', '171&1', '10&1']]\n",
      "[['127&1']]\n",
      "[['318&1', '339&1', '299&1', '293&1', '167&1']]\n",
      "[['43&1']]\n",
      "[['257&1', '327&1', '244&1', '259&1', '306&1']]\n",
      "[['263&1']]\n",
      "[['268&1', '344&1', '287&1', '237&1', '178&1']]\n",
      "[['40&1']]\n",
      "[['285&1', '750&1', '179&1', '95&1', '513&1']]\n",
      "[['81&1']]\n",
      "[['285&1', '8&1', '49&1', '0&1', '180&1']]\n",
      "[['261&1']]\n",
      "[['6&1', '1146&1', '432&1', '426&1', '55&1']]\n",
      "[['173&1']]\n",
      "[['314&1', '267&1', '339&1', '271&1', '332&1']]\n",
      "[['42&1']]\n",
      "[['285&1', '257&1', '327&1', '293&1', '288&1']]\n",
      "[['83&1']]\n",
      "[['285&1', '257&1', '299&1', '288&1', '878&1']]\n",
      "[['268&1']]\n",
      "[['514&1', '315&1', '901&1', '918&1', '339&1']]\n",
      "[['258&1']]\n",
      "[['254&1', '285&1', '297&1', '184&1', '172&1']]\n",
      "[['84&1']]\n",
      "[['285&1', '318&1', '1136&1', '13&1', '812&1']]\n",
      "[['212&1']]\n",
      "[['287&1', '257&1', '677&1', '49&1', '6&1']]\n",
      "[['120&1']]\n",
      "[['735&1', '630&1', '643&1', '99&1', '356&1']]\n",
      "[['48&1']]\n",
      "[['301&1', '345&1', '261&1', '323&1', '288&1']]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9d65a157e8c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser_histo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhisto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_histo_v4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_histo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# #     break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "for user_histo in dg.histo:\n",
    "    states, actions = sample_histo_v4(user_histo,nb_states=[5],nb_actions=[5])\n",
    "    print(states)\n",
    "    print(actions)\n",
    "# #     break\n",
    "#     for i in range(len(states)):\n",
    "#         # FORMAT STATE\n",
    "#         state_str = '|'.join (states[i])\n",
    "#         print(state_str)\n",
    "# #         FORMAT ACTION\n",
    "#         action_str = '|'.join (actions[i])\n",
    "#         print(action_str)\n",
    "#         # FORMAT N_STATE\n",
    "#         n_state_str = state_str + '|' + action_str\n",
    "#         print(n_state_str)\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_histo in dg.train:\n",
    "    states, actions = sample_histo_v2(user_histo,nb_states=[12],nb_actions=[4])\n",
    "#     print(states)\n",
    "#     print(actions)\n",
    "#     break\n",
    "    for i in range (len (states)):\n",
    "        # FORMAT STATE\n",
    "        state_str = '|'.join (states[i])\n",
    "        print(state_str)\n",
    "        # FORMAT ACTION\n",
    "        action_str = '|'.join (actions[i])\n",
    "        print(action_str)\n",
    "        # FORMAT N_STATE\n",
    "        n_state_str = state_str + '|' + action_str\n",
    "        print(n_state_str)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_histo in dg.train:\n",
    "    states, actions = sample_histo_v3(user_histo,nb_states=[12],nb_actions=[4])\n",
    "    print(len(states))\n",
    "#     print(actions)\n",
    "#     break\n",
    "    for i in range (len (states)):\n",
    "        # FORMAT STATE\n",
    "        state_str = '|'.join (states[i])\n",
    "#         print(state_str)\n",
    "        # FORMAT ACTION\n",
    "        action_str = '|'.join (actions[i])\n",
    "#         print(action_str)\n",
    "        # FORMAT N_STATE\n",
    "        n_state_str = state_str + '|' + action_str\n",
    "#         print(n_state_str)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def read_file(data_path):\n",
    "    ''' Load data from train.csv or test.csv. '''\n",
    "\n",
    "    data = pd.read_csv (data_path, sep = ';')\n",
    "    for col in ['user', 'state']:\n",
    "        data[col] = [np.array ([[np.int(k) for k in ee.split ('&')] for ee in e.split ('|')]) for e in data[col]]\n",
    "    for col in ['user', 'state']:\n",
    "        data[col] = [np.array ([e[0] for e in l]) for l in data[col]]\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv ('train.csv', sep = ';')\n",
    "for col in ['state', 'n_state', 'action_reward']:\n",
    "    data[col] = [np.array ([[np.int (k) for k in ee.split ('&')] for ee in e.split ('|')]) for e in data[col]]\n",
    "for col in ['state', 'n_state']:\n",
    "    data[col] = [np.array ([e[0] for e in l]) for l in data[col]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['state'] = [[e[0] for e in l] for l in data['action_reward']]\n",
    "\n",
    "data.drop (columns = ['action_reward'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[389]</td>\n",
       "      <td>[302, 127, 100, 50, 475, 181, 847, 1007, 1, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[894]</td>\n",
       "      <td>[242, 302, 258, 262, 879, 292, 690, 328, 300, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[384]</td>\n",
       "      <td>[272, 302, 333, 347, 286, 258, 313, 327, 300, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[658]</td>\n",
       "      <td>[515, 100, 276, 9, 127, 1, 408, 475, 257, 50, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[711]</td>\n",
       "      <td>[258, 286, 181, 50, 475, 283, 676, 1115, 476, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user                                              state\n",
       "0  [389]  [302, 127, 100, 50, 475, 181, 847, 1007, 1, 27...\n",
       "1  [894]  [242, 302, 258, 262, 879, 292, 690, 328, 300, ...\n",
       "2  [384]  [272, 302, 333, 347, 286, 258, 313, 327, 300, ...\n",
       "3  [658]  [515, 100, 276, 9, 127, 1, 408, 475, 257, 50, ...\n",
       "4  [711]  [258, 286, 181, 50, 475, 283, 676, 1115, 476, ..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-fa2358ee04fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_state'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3000\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3001\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3613\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreindexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindexer\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   3602\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3603\u001b[0m                         \u001b[0;31m# duplicate axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3604\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3606\u001b[0m                     \u001b[0;31m# other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindexer\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   3597\u001b[0m                 \u001b[0;31m# GH 4107\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3598\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3599\u001b[0;31m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3600\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3601\u001b[0m                     \u001b[0;31m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   4028\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4029\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4030\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4032\u001b[0m     def drop(\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4542\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4543\u001b[0m         return self._reindex_axes(\n\u001b[0;32m-> 4544\u001b[0;31m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4545\u001b[0m         ).__finalize__(self)\n\u001b[1;32m   4546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4565\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4566\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4567\u001b[0;31m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4568\u001b[0m             )\n\u001b[1;32m   4569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4611\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4612\u001b[0m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4613\u001b[0;31m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4614\u001b[0m             )\n\u001b[1;32m   4615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3096\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3097\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3098\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "data['n_state'] = pd.concat([copy.copy(data['user']),copy.copy(data['state'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>state</th>\n",
       "      <th>n_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[389]</td>\n",
       "      <td>[302, 127, 100, 50, 475, 181, 847, 1007, 1, 27...</td>\n",
       "      <td>[691, 516, 489, 439, 864, 570, 1236, 1396, 390...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[894]</td>\n",
       "      <td>[242, 302, 258, 262, 879, 292, 690, 328, 300, ...</td>\n",
       "      <td>[1136, 1196, 1152, 1156, 1773, 1186, 1584, 122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[384]</td>\n",
       "      <td>[272, 302, 333, 347, 286, 258, 313, 327, 300, ...</td>\n",
       "      <td>[656, 686, 717, 731, 670, 642, 697, 711, 684, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[658]</td>\n",
       "      <td>[515, 100, 276, 9, 127, 1, 408, 475, 257, 50, ...</td>\n",
       "      <td>[1173, 758, 934, 667, 785, 659, 1066, 1133, 91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[711]</td>\n",
       "      <td>[258, 286, 181, 50, 475, 283, 676, 1115, 476, ...</td>\n",
       "      <td>[969, 997, 892, 761, 1186, 994, 1387, 1826, 11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user                                              state  \\\n",
       "0  [389]  [302, 127, 100, 50, 475, 181, 847, 1007, 1, 27...   \n",
       "1  [894]  [242, 302, 258, 262, 879, 292, 690, 328, 300, ...   \n",
       "2  [384]  [272, 302, 333, 347, 286, 258, 313, 327, 300, ...   \n",
       "3  [658]  [515, 100, 276, 9, 127, 1, 408, 475, 257, 50, ...   \n",
       "4  [711]  [258, 286, 181, 50, 475, 283, 676, 1115, 476, ...   \n",
       "\n",
       "                                             n_state  \n",
       "0  [691, 516, 489, 439, 864, 570, 1236, 1396, 390...  \n",
       "1  [1136, 1196, 1152, 1156, 1773, 1186, 1584, 122...  \n",
       "2  [656, 686, 717, 731, 670, 642, 697, 711, 684, ...  \n",
       "3  [1173, 758, 934, 667, 785, 659, 1066, 1133, 91...  \n",
       "4  [969, 997, 892, 761, 1186, 994, 1387, 1826, 11...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
